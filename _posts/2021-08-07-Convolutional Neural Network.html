<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">.lst-kix_list_2-6>li:before{content:"\0025cf  "}.lst-kix_list_2-7>li:before{content:"o  "}ul.lst-kix_list_1-0{list-style-type:none}.lst-kix_list_2-4>li:before{content:"o  "}.lst-kix_list_2-5>li:before{content:"\0025aa  "}.lst-kix_list_2-8>li:before{content:"\0025aa  "}ul.lst-kix_list_2-8{list-style-type:none}ul.lst-kix_list_1-3{list-style-type:none}ul.lst-kix_list_2-2{list-style-type:none}.lst-kix_list_1-0>li:before{content:"\0025cf  "}ul.lst-kix_list_1-4{list-style-type:none}ul.lst-kix_list_2-3{list-style-type:none}ul.lst-kix_list_1-1{list-style-type:none}ul.lst-kix_list_2-0{list-style-type:none}ul.lst-kix_list_1-2{list-style-type:none}ul.lst-kix_list_2-1{list-style-type:none}ul.lst-kix_list_1-7{list-style-type:none}ul.lst-kix_list_2-6{list-style-type:none}.lst-kix_list_1-1>li:before{content:"o  "}.lst-kix_list_1-2>li:before{content:"\0025aa  "}ul.lst-kix_list_1-8{list-style-type:none}ul.lst-kix_list_2-7{list-style-type:none}ul.lst-kix_list_1-5{list-style-type:none}ul.lst-kix_list_2-4{list-style-type:none}ul.lst-kix_list_1-6{list-style-type:none}ul.lst-kix_list_2-5{list-style-type:none}.lst-kix_list_1-3>li:before{content:"\0025cf  "}.lst-kix_list_1-4>li:before{content:"o  "}.lst-kix_list_1-7>li:before{content:"o  "}.lst-kix_list_1-5>li:before{content:"\0025aa  "}.lst-kix_list_1-6>li:before{content:"\0025cf  "}li.li-bullet-0:before{margin-left:-18pt;white-space:nowrap;display:inline-block;min-width:18pt}.lst-kix_list_2-0>li:before{content:"-  "}.lst-kix_list_2-1>li:before{content:"o  "}.lst-kix_list_1-8>li:before{content:"\0025aa  "}.lst-kix_list_2-2>li:before{content:"\0025aa  "}.lst-kix_list_2-3>li:before{content:"\0025cf  "}ol{margin:0;padding:0}table td,table th{padding:0}.c8{margin-left:108pt;padding-top:0pt;text-indent:36pt;padding-bottom:8pt;line-height:1.0791666666666666;orphans:2;widows:2;text-align:left}.c7{margin-left:90pt;padding-top:0pt;text-indent:18pt;padding-bottom:0pt;line-height:1.0791666666666666;orphans:2;widows:2;text-align:justify}.c18{margin-left:54pt;padding-top:0pt;padding-bottom:0pt;line-height:1.0791666666666666;orphans:2;widows:2;text-align:left}.c2{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Calibri";font-style:normal}.c16{margin-left:36pt;padding-top:0pt;padding-bottom:0pt;line-height:1.0791666666666666;orphans:2;widows:2;text-align:left}.c4{margin-left:54pt;padding-top:0pt;padding-bottom:0pt;line-height:1.0791666666666666;orphans:2;widows:2;text-align:justify}.c1{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:14pt;font-family:"Calibri";font-style:normal}.c9{padding-top:0pt;padding-bottom:8pt;line-height:1.0791666666666666;orphans:2;widows:2;text-align:left;height:11pt}.c22{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:20pt;font-family:"Calibri";font-style:normal}.c0{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:14pt;font-family:"Calibri";font-style:normal}.c23{padding-top:0pt;padding-bottom:8pt;line-height:1.0791666666666666;orphans:2;widows:2;text-align:center}.c20{padding-top:0pt;padding-bottom:0pt;line-height:1.0791666666666666;orphans:2;widows:2;text-align:left}.c5{padding-top:0pt;padding-bottom:8pt;line-height:1.0791666666666666;orphans:2;widows:2;text-align:justify}.c15{padding-top:0pt;padding-bottom:8pt;line-height:1.0791666666666666;orphans:2;widows:2;text-align:left}.c3{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.c14{margin-left:126pt;text-indent:18pt}.c12{padding:0;margin:0}.c13{font-size:14pt;font-weight:700}.c11{text-indent:36pt}.c21{margin-left:54pt}.c10{height:11pt}.c17{font-size:14pt}.c19{margin-left:36pt}.c6{padding-left:0pt}.title{padding-top:24pt;color:#000000;font-weight:700;font-size:36pt;padding-bottom:6pt;font-family:"Calibri";line-height:1.0791666666666666;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:18pt;color:#666666;font-size:24pt;padding-bottom:4pt;font-family:"Georgia";line-height:1.0791666666666666;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Calibri"}p{margin:0;color:#000000;font-size:11pt;font-family:"Calibri"}h1{padding-top:24pt;color:#000000;font-weight:700;font-size:24pt;padding-bottom:6pt;font-family:"Calibri";line-height:1.0791666666666666;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-weight:700;font-size:18pt;padding-bottom:4pt;font-family:"Calibri";line-height:1.0791666666666666;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:14pt;color:#000000;font-weight:700;font-size:14pt;padding-bottom:4pt;font-family:"Calibri";line-height:1.0791666666666666;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:12pt;color:#000000;font-weight:700;font-size:12pt;padding-bottom:2pt;font-family:"Calibri";line-height:1.0791666666666666;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:11pt;color:#000000;font-weight:700;font-size:11pt;padding-bottom:2pt;font-family:"Calibri";line-height:1.0791666666666666;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:10pt;color:#000000;font-weight:700;font-size:10pt;padding-bottom:2pt;font-family:"Calibri";line-height:1.0791666666666666;page-break-after:avoid;orphans:2;widows:2;text-align:left}</style></head><body class="c3"><p class="c23"><span class="c22">Convolutional Neural Network</span></p><p class="c9"><span class="c0"></span></p><p class="c15"><span class="c1">Motivation</span></p><ul class="c12 lst-kix_list_1-0 start"><li class="c16 c6 li-bullet-0"><span class="c0">a digital image is 2D grid image , since neural network expects a vector as input , one idea to deal with images would be to flatten that image and feed the output of the flattening operation to the neural network and this would work to some extent </span></li></ul><p class="c16 c10"><span class="c1"></span></p><p class="c8"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 250.00px; height: 190.00px;"><img alt="Chart, bar chart

Description automatically generated" src="{{ site.baseurl }}/assets/Convolutional Neural Network/image1.png" style="width: 200.00px; height: 189.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c15"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 11.93px;"><img src="{{ site.baseurl }}/assets/Convolutional Neural Network/image3.png" style="width: 624.00px; height: 30px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c15"><span class="c13">&nbsp;</span><span class="c0">But eventually ,that flattened vector won&rsquo;t be the same for a translated image </span></p><p class="c15"><span class="c17">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 197.00px; height: 189.00px;"><img alt="A picture containing shoji, building, window

Description automatically generated" src="{{ site.baseurl }}/assets/Convolutional Neural Network/image2.png" style="width: 197.00px; height: 189.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c15"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 11.93px;"><img src="{{ site.baseurl }}/assets/Convolutional Neural Network/image5.png" style="width: 624.00px; height: 30px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c15"><span class="c0">The neural network would have to learn very different parameters in order to classify the objects , which Is difficult job since natural images are very variant (lightning, translated , angles &hellip;..)</span></p><p class="c15"><span class="c0">Also it is worth mentioning that the input Vector would be relatively big 64*64*3(RGB images) which can cause problem with memory while using neural network since we will have in The first layer with just 10 neurons alone (64*64*3*10) Weights to train</span></p><p class="c9"><span class="c1"></span></p><p class="c15"><span class="c13">Natural images </span><span class="c0">have 2 main characteristics </span></p><ul class="c12 lst-kix_list_1-0"><li class="c16 c6 li-bullet-0"><span class="c0">Locality : nearby pixels are more strongly correlated </span></li><li class="c6 c16 li-bullet-0"><span class="c0">Translation invariance: meaningful patterns can occur anywhere in the image</span></li></ul><p class="c9 c19"><span class="c0"></span></p><p class="c15"><span class="c1">How Convolutional Neural Network solve The problem for images ?</span></p><ul class="c12 lst-kix_list_1-0"><li class="c16 c6 li-bullet-0"><span class="c0">The answer to this question is 3 characteristics of The CNN </span></li></ul><ul class="c12 lst-kix_list_2-0 start"><li class="c18 c6 li-bullet-0"><span class="c0">Sparse Connectivity :</span><span class="c2">&nbsp;when processing an image, the input image might have thousands or millions of pixels, but we can detect small, meaningful features such as edges with kernels that occupy only tens or hundreds of pixels. This means that we need to store fewer parameters, which both reduces the memory requirements of the model and improves its statistical efficiency. It also means that computing the output requires fewer operations. These improvements in efficiency are usually quite large. If there are m inputs and n outputs, then matrix multiplication requires m&times;n parameters and the algorithms used in practice have O(m &times; n) runtime (per example). If we limit the number of connections each output may have to k, then the sparsely connected approach requires only k &times; n parameters and O(k &times; n) runtime</span></li></ul><p class="c18 c10"><span class="c2"></span></p><p class="c15 c21"><span class="c2">Fully Connected &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; VS &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Sparsely connected</span></p><p class="c15 c19"><span>&nbsp; </span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 281.81px; height: 124.79px;"><img alt="Chart, diagram

Description automatically generated" src="{{ site.baseurl }}/assets/Convolutional Neural Network/image4.png" style="width: 281.81px; height: 124.79px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 239.34px; height: 108.31px;"><img alt="Diagram

Description automatically generated" src="{{ site.baseurl }}/assets/Convolutional Neural Network/image7.png" style="width: 239.34px; height: 108.31px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c9 c19"><span class="c2"></span></p><ul class="c12 lst-kix_list_2-0"><li class="c18 c6 li-bullet-0"><span class="c0">Parameter sharing : </span><span class="c2">In a convolutional neural net, each member of the kernel is used at every position of the input (except perhaps some of the boundary pixels, depending on the design decisions regarding the boundary). The parameter sharing used by the convolution operation means that rather than learning a separate set of parameters for every location, we learn only one set. This does not affect the runtime of forward propagation&mdash;it is still O(k &times; n)&mdash;but it does further reduce the storage requirements of the model to k parameters</span></li><li class="c6 c18 li-bullet-0"><span class="c0">Equivariance : </span><span class="c2">In the case of convolution, the particular form of parameter sharing causes the layer to have a property called equivariance to translation. use the same network parameters to detect local patterns at many locations in the image</span></li></ul><p class="c14 c20"><span class="c2">&nbsp;</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 195.27px; height: 294.38px;"><img alt="" src="{{ site.baseurl }}/assets/Convolutional Neural Network/image6.png" style="width: 195.27px; height: 294.38px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c9 c14"><span class="c2"></span></p><p class="c5"><span class="c1">The Convolution Operation</span></p><p class="c5"><span class="c0">So in Practical set , the convolutional operation is implemented by making The kernel slides across The image and produces an output Value at each position</span></p><p class="c5 c11"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 558.63px; height: 238.01px;"><img alt="A picture containing text, shoji, crossword puzzle

Description automatically generated" src="{{ site.baseurl }}/assets/Convolutional Neural Network/image9.png" style="width: 558.63px; height: 238.01px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c5 c10"><span class="c0"></span></p><p class="c5"><span class="c0">Also we convolve different Kernels and as a result obtain Different feature maps or channels </span></p><p class="c5"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 263.87px;"><img alt="Chart

Description automatically generated with low confidence" src="{{ site.baseurl }}/assets/Convolutional Neural Network/image8.png" style="width: 624.00px; height: 263.87px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c5"><span class="c0">&nbsp;</span></p><p class="c5"><span class="c1">Variants of The Convolution Operation :</span></p><ul class="c12 lst-kix_list_2-0"><li class="c4 c6 li-bullet-0"><span class="c5">Valid Convolution : </span><span class="c2">Doesn&rsquo;t used any padding</span></li></ul><p class="c4 c10"><span class="c2"></span></p><p class="c4"><span class="c2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 290.57px; height: 190.07px;"><img alt="A picture containing diagram

Description automatically generated" src="{{ site.baseurl }}/assets/Convolutional Neural Network/image12.png" style="width: 290.57px; height: 190.07px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c4 c10"><span class="c2"></span></p><p class="c4 c10"><span class="c2"></span></p><p class="c4 c10"><span class="c2"></span></p><p class="c4 c10"><span class="c2"></span></p><ul class="c12 lst-kix_list_2-0"><li class="c4 c6 li-bullet-0"><span class="c5">Same Convolution : </span><span class="c2">pads in a way that the input size is the same as the output size</span></li></ul><p class="c4 c10"><span class="c2"></span></p><p class="c4"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 263.14px; height: 176.70px;"><img alt="A screenshot of a computer

Description automatically generated with medium confidence" src="{{ site.baseurl }}/assets/Convolutional Neural Network/image10.png" style="width: 263.14px; height: 176.70px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c4 c10"><span class="c2"></span></p><ul class="c12 lst-kix_list_2-0"><li class="c4 c6 li-bullet-0"><span class="c5">Full Convolution : </span><span class="c2">we compute output wherever the kernel and the output overlap by atleast 1 pixel</span><p class="c4"><span class="c2">&nbsp;</span></p><p class="c7"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 361.55px; height: 244.75px;"><img alt="Chart, bar chart

Description automatically generated" src="{{ site.baseurl }}/assets/Convolutional Neural Network/image11.png" style="width: 361.55px; height: 244.75px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c7 c10"><span class="c2"></span></p><ul class="c12 lst-kix_list_2-0"><li class="c4 c6 li-bullet-0"><span class="c5">Strided Convolution : </span><span class="c2">: kernel slides along the image with a step &gt; 1</span></li></ul><p class="c4 c10"><span class="c0"></span></p><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 240.97px; height: 113.40px;"><img alt="A picture containing shoji, building, clipart

Description automatically generated" src="{{ site.baseurl }}/assets/Convolutional Neural Network/image13.png" style="width: 240.97px; height: 113.40px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 219.74px; height: 110.13px;"><img alt="A picture containing shoji, building, clipart

Description automatically generated" src="{{ site.baseurl }}/assets/Convolutional Neural Network/image14.png" style="width: 219.74px; height: 110.13px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c4 c10"><span class="c0"></span></p><p class="c4 c10"><span class="c0"></span></p><ul class="c12 lst-kix_list_2-0"><li class="c4 c6 li-bullet-0"><span class="c5">Dilated Convolution : </span><span class="c2">: kernel is spread out, step &gt; 1 between kernel elements</span></li></ul><p class="c4"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 323.57px; height: 149.78px;"><img alt="A picture containing shoji, clipart

Description automatically generated" src="{{ site.baseurl }}/assets/Convolutional Neural Network/image15.png" style="width: 323.57px; height: 149.78px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c4 c10"><span class="c0"></span></p><ul class="c12 lst-kix_list_2-0"><li class="c4 c6 li-bullet-0"><span class="c5">Depth wise Convolution : </span><span class="c2">each output channel is connected only to one input channel</span></li></ul><p class="c4"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 335.03px; height: 224.77px;"><img alt="Diagram, engineering drawing

Description automatically generated" src="{{ site.baseurl }}/assets/Convolutional Neural Network/image16.png" style="width: 335.03px; height: 224.77px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c5 c10 c21"><span class="c2"></span></p><p class="c5"><span class="c1">Pooling </span></p><p class="c5"><span class="c2">A pooling function replaces the output of the net at a certain location with a summary statistic of the nearby outputs. For example, the max pooling operation reports the maximum output within a rectangular neighborhood. Other popular pooling functions include the average of a rectangular neighborhood, the L2 norm of a rectangular neighborhood, or a weighted average based on the distance from the central pixel. In all cases, pooling helps to make the representation become approximately invariant to small translations of the input. Invariance to translation means that if we translate the input by a small amount, the values of most of the pooled outputs do not change.</span></p><p class="c5"><span class="c13">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 363.56px; height: 194.32px;"><img alt="A picture containing square

Description automatically generated" src="{{ site.baseurl }}/assets/Convolutional Neural Network/image17.png" style="width: 363.56px; height: 194.32px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c9"><span class="c1"></span></p><p class="c9"><span class="c0"></span></p></body></html>